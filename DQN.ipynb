{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DQN_Acrobot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Result at Episode 21, Time step 10359\n",
      "Avg Reward in 10 Episodes: -88.0\n",
      "Avg Time Step Each Episode: 89.0\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.9015895\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 45, Time step 20197\n",
      "Avg Reward in 10 Episodes: -145.4\n",
      "Avg Time Step Each Episode: 146.3\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.8081285\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 74, Time step 30277\n",
      "Avg Reward in 10 Episodes: -89.3\n",
      "Avg Time Step Each Episode: 90.3\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.7123685\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 109, Time step 40120\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.61886\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 152, Time step 50127\n",
      "Avg Reward in 10 Episodes: -184.4\n",
      "Avg Time Step Each Episode: 185.2\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.5237935\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 208, Time step 60118\n",
      "Avg Reward in 10 Episodes: -221.4\n",
      "Avg Time Step Each Episode: 222.1\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.4288790000000001\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 271, Time step 70088\n",
      "Avg Reward in 10 Episodes: -88.0\n",
      "Avg Time Step Each Episode: 89.0\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.3341640000000001\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 352, Time step 80063\n",
      "Avg Reward in 10 Episodes: -93.9\n",
      "Avg Time Step Each Episode: 94.9\n",
      "Final Result: -88.0\n",
      "Epsilon: 0.23940150000000004\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 432, Time step 90063\n",
      "Avg Reward in 10 Episodes: -85.8\n",
      "Avg Time Step Each Episode: 86.8\n",
      "Final Result: -85.8\n",
      "Epsilon: 0.14440150000000007\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 525, Time step 100009\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "Final Result: -85.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 631, Time step 110054\n",
      "Avg Reward in 10 Episodes: -84.8\n",
      "Avg Time Step Each Episode: 85.8\n",
      "Final Result: -84.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 727, Time step 120071\n",
      "Avg Reward in 10 Episodes: -76.9\n",
      "Avg Time Step Each Episode: 77.9\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 833, Time step 130038\n",
      "Avg Reward in 10 Episodes: -85.2\n",
      "Avg Time Step Each Episode: 86.2\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 931, Time step 140016\n",
      "Avg Reward in 10 Episodes: -144.5\n",
      "Avg Time Step Each Episode: 145.4\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1039, Time step 150030\n",
      "Avg Reward in 10 Episodes: -298.0\n",
      "Avg Time Step Each Episode: 298.5\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1143, Time step 160012\n",
      "Avg Reward in 10 Episodes: -77.9\n",
      "Avg Time Step Each Episode: 78.9\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1240, Time step 170055\n",
      "Avg Reward in 10 Episodes: -98.8\n",
      "Avg Time Step Each Episode: 99.8\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1344, Time step 180078\n",
      "Avg Reward in 10 Episodes: -89.3\n",
      "Avg Time Step Each Episode: 90.3\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1453, Time step 190032\n",
      "Avg Reward in 10 Episodes: -94.8\n",
      "Avg Time Step Each Episode: 95.8\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1560, Time step 200044\n",
      "Avg Reward in 10 Episodes: -88.5\n",
      "Avg Time Step Each Episode: 89.5\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1676, Time step 210080\n",
      "Avg Reward in 10 Episodes: -83.8\n",
      "Avg Time Step Each Episode: 84.8\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1791, Time step 220074\n",
      "Avg Reward in 10 Episodes: -78.7\n",
      "Avg Time Step Each Episode: 79.7\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 1900, Time step 230072\n",
      "Avg Reward in 10 Episodes: -253.2\n",
      "Avg Time Step Each Episode: 253.8\n",
      "Final Result: -76.9\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2011, Time step 240079\n",
      "Avg Reward in 10 Episodes: -71.8\n",
      "Avg Time Step Each Episode: 72.8\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2124, Time step 250051\n",
      "Avg Reward in 10 Episodes: -75.6\n",
      "Avg Time Step Each Episode: 76.6\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2239, Time step 260053\n",
      "Avg Reward in 10 Episodes: -84.2\n",
      "Avg Time Step Each Episode: 85.2\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2351, Time step 270058\n",
      "Avg Reward in 10 Episodes: -76.9\n",
      "Avg Time Step Each Episode: 77.9\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2462, Time step 280063\n",
      "Avg Reward in 10 Episodes: -459.0\n",
      "Avg Time Step Each Episode: 459.1\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2570, Time step 290067\n",
      "Avg Reward in 10 Episodes: -77.3\n",
      "Avg Time Step Each Episode: 78.3\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2680, Time step 300012\n",
      "Avg Reward in 10 Episodes: -86.6\n",
      "Avg Time Step Each Episode: 87.6\n",
      "Final Result: -71.8\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2792, Time step 310003\n",
      "Avg Reward in 10 Episodes: -71.2\n",
      "Avg Time Step Each Episode: 72.2\n",
      "Final Result: -71.2\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 2902, Time step 320039\n",
      "Avg Reward in 10 Episodes: -73.7\n",
      "Avg Time Step Each Episode: 74.7\n",
      "Final Result: -71.2\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at Episode 3014, Time step 330002\n",
      "Avg Reward in 10 Episodes: -81.3\n",
      "Avg Time Step Each Episode: 82.3\n",
      "Final Result: -71.2\n",
      "Epsilon: 0.05\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
