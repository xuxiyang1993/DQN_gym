{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQN_Acrobot import *\n",
    "from LSTM_Acrobot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Result at 50177\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 100460\n",
      "Avg Reward in 10 Episodes: -482.8\n",
      "Avg Time Step Each Episode: 482.9\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 150470\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 200284\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 250137\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 300352\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 350162\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 400262\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 450313\n",
      "Avg Reward in 10 Episodes: -226.7\n",
      "Avg Time Step Each Episode: 227.5\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 500434\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 550182\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 600165\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 650444\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 700255\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 750400\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 800288\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 850020\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 900249\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 950145\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1000454\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1050308\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1100295\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1150057\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1200034\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1250095\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1300076\n",
      "Avg Reward in 10 Episodes: -78.9\n",
      "Avg Time Step Each Episode: 79.9\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1350022\n",
      "Avg Reward in 10 Episodes: -84.9\n",
      "Avg Time Step Each Episode: 85.9\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1400036\n",
      "Avg Reward in 10 Episodes: -96.6\n",
      "Avg Time Step Each Episode: 97.6\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1450065\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1500065\n",
      "Avg Reward in 10 Episodes: -90.8\n",
      "Avg Time Step Each Episode: 91.8\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1550061\n",
      "Avg Reward in 10 Episodes: -94.7\n",
      "Avg Time Step Each Episode: 95.7\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1600055\n",
      "Avg Reward in 10 Episodes: -256.8\n",
      "Avg Time Step Each Episode: 257.4\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1650007\n",
      "Avg Reward in 10 Episodes: -77.8\n",
      "Avg Time Step Each Episode: 78.8\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1700034\n",
      "Avg Reward in 10 Episodes: -261.3\n",
      "Avg Time Step Each Episode: 261.9\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1750014\n",
      "Avg Reward in 10 Episodes: -330.8\n",
      "Avg Time Step Each Episode: 331.2\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1800055\n",
      "Avg Reward in 10 Episodes: -68.1\n",
      "Avg Time Step Each Episode: 69.1\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1850054\n",
      "Avg Reward in 10 Episodes: -80.1\n",
      "Avg Time Step Each Episode: 81.1\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1900211\n",
      "Avg Reward in 10 Episodes: -500.0\n",
      "Avg Time Step Each Episode: 500.0\n",
      "-------------------------------------------\n",
      "Model Evaluation Result at 1950058\n",
      "Avg Reward in 10 Episodes: -82.9\n",
      "Avg Time Step Each Episode: 83.9\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_model('save_model/-64.h5')\n",
    "ob = env.reset()\n",
    "agent.model.predict(ob.reshape([1, agent.state_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Result at 0\n",
      "Avg Reward in 10 Episodes: -81.7\n",
      "Avg Time Step Each Episode: 82.7\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
